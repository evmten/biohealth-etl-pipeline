ğŸ¥ Public Health Data Pipeline (ETL + Airflow + SQLite)
This project builds a local ETL pipeline that ingests, transforms, and loads public health data using Python, Airflow, and SQLite. It showcases essential data engineering skills such as orchestration, modular pipeline design, and validation.

ğŸš€ Features
Modular Python ETL scripts

Airflow orchestration via Docker

Ingestion from API, CSV, and scraped sources

SQLite storage with raw and clean layers

Basic SQL analytics

Lightweight validation using pytest

ğŸ“Š Architecture

ğŸ“‚ Project Structure
css
Copy
Edit
pipeline-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ cleaned/
â”‚   â””â”€â”€ health_data.db
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ ingest.py
â”‚   â””â”€â”€ transformation/
â”‚       â””â”€â”€ transform.py
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ airflow/
â”‚       â”œâ”€â”€ dags/
â”‚       â”‚   â”œâ”€â”€ health_pipeline_dag.py
â”‚       â”‚   â”œâ”€â”€ run_etl.py
â”‚       â”‚   â””â”€â”€ validate_data.py
â”‚       â”‚   â””â”€â”€ validate_pipeline_dag.py
â”‚       â””â”€â”€ tests/
â”‚           â””â”€â”€ test_transform.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ“Œ Data Sources
OECD API: Life expectancy data

IQAir API: Air quality index

Wikipedia (scraped): Health expenditure by country

ğŸ› ï¸ Tools & Tech

Tool	Purpose
Python	ETL logic
Pandas	Transformation
SQLite	Lightweight DB
Docker	Containerized Airflow
Apache Airflow	Orchestration & scheduling
Pytest	Basic data validation
ğŸ” Workflow Overview
Ingestion: Download data via API, CSV, and scraping

Transformation: Clean and harmonize datasets into one schema

Load: Save raw and cleaned data into SQLite

Orchestration: Run full pipeline using Airflow DAG

Validation: Basic checks with pytest

âœ… Example Queries
sql
Copy
Edit
-- Top 5 countries by life expectancy
SELECT Country, LifeExpectancy
FROM health_data
ORDER BY LifeExpectancy DESC
LIMIT 5;

-- Compare raw vs clean datasets
SELECT DISTINCT Location
FROM raw_health_expenditure
EXCEPT
SELECT DISTINCT Country
FROM merged_health_data;
ğŸ§ª Running Tests
bash
Copy
Edit
cd docker/airflow
pytest tests/
ğŸ³ Running Airflow
bash
Copy
Edit
cd docker
docker-compose up -d
Then open your browser at: http://localhost:8080
Login with your admin user and trigger the DAG.